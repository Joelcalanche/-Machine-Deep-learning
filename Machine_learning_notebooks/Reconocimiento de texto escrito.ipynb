{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-pricing",
   "metadata": {},
   "source": [
    "# El dataset de MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sexual-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "closing-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-7e0ebff3f7e1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\calanche\\Desktop\\heart-disease-project\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\calanche\\Desktop\\heart-disease-project\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\calanche\\Desktop\\heart-disease-project\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MINIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\calanche\\Desktop\\heart-disease-project\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MINIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\calanche\\Desktop\\heart-disease-project\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MINIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MINIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\calanche\\Desktop\\heart-disease-project\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MINIST_data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lesbian-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "composed-consumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alternate-sperm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
       "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
       "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
       "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
       "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
       "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
       "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
       "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
       "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
       "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
       "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
       "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Las imagenes de este data set vienen en formato unidimesional, hay que cambiarlo a tipo foto\n",
    "im_temp = mnist.train.images[0]\n",
    "im_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sophisticated-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sexual-network",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25ecd8b8978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# la cambiamos al formato foto\n",
    "io.imshow(np.reshape(im_temp, (28,28)))\n",
    "\n",
    "# en lugar de pensar en una matriz de 28x28, podemos pensar en un array aplanado de 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "academic-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-portfolio",
   "metadata": {},
   "source": [
    "# Una red neuronal con Tensor Flow - v1\n",
    "* Las imagenes de entrenamiento del MNISt viven en un espacio vectorial de dimension 784.\n",
    "* El dataset se puede pensar como 55000 filas y 784 columnas(28*28), lo podemos pensar como un dataset, cada una de las entradas del tensor es un pixel con intensidad entre 0 y 1\n",
    "* cada dato del dataset es un numero real entre 0 y 1\n",
    "* one_hot = es un vector que es 0 en la gran mayoria de las dimensiones y 1 en solo una de las dimensiones\n",
    "\n",
    "Y = softmax(w * x + b), donde w es la matriz de pesos, y b es la desviacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adopted-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = 784\n",
    "n_categories = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "revolutionary-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow en lugar de ejecutar una operacion unica independiente fuera de pyton, muy pesada\n",
    "\n",
    "# Tensorflow lo que hace es describir un grafo interconectado de operaciones que se ejecutan todas y cada una de ellas fuera de python\n",
    "# esto para evitar hacer operaciones fuera y devolver a python y asi\n",
    "# cuando arranca una sesion y se elevoran los calculos y luego finaliza la sesion, las operaciones se realizan fuera de python\n",
    "# para describir las operaciones utlizamos los placeholder\n",
    "\n",
    "# con el None le decimos que pudiera tener cualquier longitud\n",
    "x = tf.placeholder(tf.float32, [None, dim_input])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "opened-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tendremos  tantas filas como posibles categorias a clasificar\n",
    "# y el numero de filas debera ser igual al mimsmo numero de columnas del vector x\n",
    "# nos inicializamos en 0 como punto de partida\n",
    "w = tf.Variable(tf.zeros([dim_input,n_categories]))\n",
    "\n",
    "b = tf.Variable(tf.zeros([n_categories]))\n",
    "\n",
    "# una variable es un tensor que se puede modificar por la propia red neuronal\n",
    "\n",
    "# la salida en esta caso seran vectores de espacio vectorial 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "african-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matmul, multiplicacion de matrices\n",
    "# lo colocamos al reves para que puedan multiplicarse(numero de columnas del primero igual al numero de filas del segundo)\n",
    "softmax_args = tf.matmul(x,w) + b\n",
    "y_hat= tf.nn.softmax(softmax_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-vietnamese",
   "metadata": {},
   "source": [
    "### Ahora tensorflow esta preparado para ejecutar lo que le hemos indicado "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-tongue",
   "metadata": {},
   "source": [
    "#### Entrenamiento de una red neuronal\n",
    "* Loss/Cost<- objetivo minimizar las perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "perceived-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-delay",
   "metadata": {},
   "source": [
    "**Una forma muy comun de hacer la clasificacion es determinar la funcion de perdidas a travez de la entropia cruzada**\n",
    "\n",
    "esta surge de pensar en el como se comprimen los codigos en teoria de la informacion sin sufrir perdidas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "retired-healing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle H_{y}(\\hat{y}) = -\\sum_{i} y_i Log(\\hat{y_i})$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Math(r\"H_{y}(\\hat{y}) = -\\sum_{i} y_i Log(\\hat{y_i})\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-reasoning",
   "metadata": {},
   "source": [
    "tipicamente no definimos que es un modelo bueno, definimos que es lo que hace a un modelo malo, el coste o perdida(loss), representa como de lejos\n",
    "esta la salida que nosotros deseamos, y lo que hacemos es minimizar dicho error\n",
    "\n",
    "La entropia cruzada mide como de ineficiente son nuestras predicciones al describir la realidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "starting-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# el none significa que puede ser cualquier cantidad de datos\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "final-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.log en este caso calcula el logaritmo de cada uno de los elementos de las predicciones\n",
    "# luego multiplicamos por el valor original, la funcion reduce_sum, sumara todos los elementos\n",
    "# solo de la segunda dimension [1] y el reduce_mean, calculara el promedio de todas las muestras del dataset\n",
    "cross_entropy = tf.reduce_mean( - tf.reduce_sum(y_ * tf.log(y_hat), reduction_indices = [1]))\n",
    "\n",
    "# tambien podemos usar\n",
    "#tf.nn.softmax_cross_entropy_with_logits(softmax_args, y_), este es mas eficiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "verified-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retropropagacion\n",
    "# le pedimos a tensorflow la entropia cruzada(el coste), utilizando el gradiente descendiente\n",
    "# con ratio de aprendisaje de 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "# tensorflow a;adira nuevas operaciones al grafo que implementaran propagacion hacia atras y gradiente descendiente\n",
    "# de modo que en cada operacion, se ejecutara un paso con gradiente descendiente con una modificacion adicional de los pesos y el bias que reduzca la perdida\n",
    "# esto indica el como sera entrenada la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "clear-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "spare-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializacion global\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "continuing-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En cada etapa del bucle tomamos una muestra de 100 datos aleatorios del dataset\n",
    "# luego ejecutamos la funcion que hemos definido sobre las imagenes que son sustutidas como placeholder de la variable x \n",
    "#batch_y es la muestra de 100 etiquetas correspondientes a las imagenes\n",
    "# cuando utilizamos peque;os batches aleatorios del dataset se llama hacer un entramiento estocaistico, en lugar de hacerlo de golpe\n",
    "# En nuestro caso es un gradiente descendiente estocaistico, lo hacemos asi en lugar en lugar de usar todo el dataset\n",
    "# para reducir el costo computacional, es como una crossvalidation\n",
    "for _ in range(5000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(100)\n",
    "    session.run(train_step, feed_dict ={\n",
    "        x: batch_x, y_: batch_y\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-witness",
   "metadata": {},
   "source": [
    "# Evaluando la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fleet-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Esto me retornara una lista de booleanos, basicamente estamos comparando las prediciones con las reales\n",
    "# argmax me devuelve la clase mas probable\n",
    "correct_predictions = tf.equal(tf.argmax(y_hat,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "explicit-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "scenic-rogers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202\n"
     ]
    }
   ],
   "source": [
    "print(session.run(accuracy, feed_dict={\n",
    "    x:mnist.test.images,\n",
    "    y_:mnist.test.labels\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-renaissance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
